cleanup = 'deep'

process {
    queue = 'premium'
    penv = 'span[hosts=1]'
    clusterOptions = "-P acc_kennylab"
    cpus = 1
    memory = '10 GB'
    time = '1h'
    
    beforeScript = '''
    source /sc/arion/projects/igh/kennylab/christa/miniforge/etc/profile.d/conda.sh
    conda activate /sc/arion/projects/igh/kennylab/christa/miniforge/envs/regenie_env
    '''
    
    // Increase maxForks significantly for high parallelization
    maxForks = 10000  // Or even higher if your cluster can handle it
    
    // Process-specific settings for your main analysis
    withName: 'run_analysis_per_chr' {
        maxForks = 10000
        stageInMode = 'copy'  // Copy files instead of symlinking
        // Consider reducing resources per job if you have many
        memory = '8 GB'
        time = '45m'
    }
    
    withName: 'combine_and_cleanup' {
        maxForks = 100  // Fewer needed for this step
        memory = '4 GB'
        time = '15m'
    }
}

executor {
    queueSize = 50000        // Increase queue size dramatically
    submitRateLimit = '2000/sec' // Increase submission rate
    pollInterval = '1 sec'   // Check job status more frequently
    
    // LSF-specific optimizations
    perJobMemLimit = true
    exitReadTimeout = '300 sec'
    
    // For LSF, consider these additional settings
    $lsf {
        queueSize = 50000
        submitRateLimit = '2000/sec'
        pollInterval = '1 sec'
    }
}

profiles {
    lsf {
        process.executor = 'lsf'
        
        // LSF-specific process settings
        process {
            // Remove the job array specification - let Nextflow handle job creation
            clusterOptions = "-P acc_kennylab"
            
            // Enable faster job submission
            beforeScript = '''
            source /sc/arion/projects/igh/kennylab/christa/miniforge/etc/profile.d/conda.sh
            conda activate /sc/arion/projects/igh/kennylab/christa/miniforge/envs/regenie_env
            '''
        }
    }
    
    standard {
        process.executor = 'local'
    }
    
    // Add a high-throughput profile
    highthroughput {
        process.executor = 'lsf'
        process.maxForks = 20000
        executor.queueSize = 100000
        executor.submitRateLimit = '5000/sec'
        
        process {
            // Optimize for many small jobs
            memory = '6 GB'
            time = '30m'
            cpus = 1
            
            // Remove job array specification here too
            clusterOptions = "-P acc_kennylab"
            
            // Use shorter queue if available
            queue = 'express'  // Change this to your cluster's fast queue
        }
    }
}